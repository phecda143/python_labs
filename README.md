# python_labs



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
name = input('–ò–º—è: ')
age = int(input('–í–æ–∑—Ä–∞—Å—Ç: '))
print(f'–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age+1}.')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/01_greeting.png)


### –ó–∞–¥–∞–Ω–∏–µ 2
```python
num1 = float(input('a: ').replace(',', '.'))
num2 = float(input('b: ').replace(',', '.'))
print(f'sum={round(num1+num2, 2)}; avg={round((num1+num2)/2, 2)}')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab01/02_sum_avg.png)


### –ó–∞–¥–∞–Ω–∏–µ 3
```python
price = float(input())
discount = float(input())
vat = float(input())
base = round((price * (1 - discount / 100)), 2)
vat_amount = round((base * (vat / 100)), 2)
total = round((base + vat_amount), 2)
print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {"{:.2f}".format(base)} ‚ÇΩ")
print(f"–ù–î–°:               {"{:.2f}".format(vat_amount)} ‚ÇΩ")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:    {"{:.2f}".format(total)} ‚ÇΩ")

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab01/03_discount_vat.png)


### –ó–∞–¥–∞–Ω–∏–µ 4
```python
m = int(input('–ú–∏–Ω—É—Ç—ã: '))
print(f'{m//60}:{(m-(m//60)*60):02d}')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](./images/lab01/04_minutes_to_hhmm.png)


### –ó–∞–¥–∞–Ω–∏–µ 5
```python
name = input('–§–ò–û:').upper().split()
print(f'–ò–Ω–∏—Ü–∏–∞–ª—ã: {name[0][0]}{name[1][0]}{name[2][0]}')
print(f'–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {sum(map(len, name))+2}')

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](./images/lab01/05_initials_and_len.png)


### –ó–∞–¥–∞–Ω–∏–µ 6
```python
n = int(input())
distance = 0
full_time = 0
for i in range(n):
    student = input().split()
    if student[-1]=='True':
        full_time += 1
    elif student[-1]=="False":
        distance += 1
print(full_time, distance)
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](./images/lab01/06_task.png)


### –ó–∞–¥–∞–Ω–∏–µ 7
```python
s = input()
first_letter_pos = -1
for i, char in enumerate(s):
    if char.isupper():
        first_letter_pos = i
        break
second_letter_pos = -1
for i, char in enumerate(s):
    if char.isdigit() and i != len(s) - 1:
        second_letter_pos = i + 1
        break
print(s[first_letter_pos:-1:second_letter_pos - first_letter_pos] + '.')

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 7](./images/lab01/07_task.png)



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if isinstance(nums, list) and len(nums) != 0 \
            and all(isinstance(item, (int, float)) for item in nums):
        return min(nums), max(nums)
    return 'ValueError'


def unique_sorted(nums: list[float | int]) -> list[float | int]:
    if isinstance(nums, list) and len(nums) != 0 \
            and all(isinstance(item, (int, float)) for item in nums):
        return sorted(set(nums))
    return nums


def flatten(mat: list[list | tuple]) -> list:
    if isinstance(mat, (list, tuple)) and len(mat) != 0 \
            and all(isinstance(item, (list, tuple)) for item in mat):
        result = []
        for item in mat:
            result.extend(item)
        return result
    return 'TypeError'
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2.1](./images/lab02/arrays2.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2.1](./images/lab02/arrays.png)


### –ó–∞–¥–∞–Ω–∏–µ 2
```python
def transpose(mat: list[list[float | int]]) -> list[list]:
    if len(mat) == 0:
        return []
    if isinstance(mat, list) and all(isinstance(row, list) for row in mat) and all(
            isinstance(item, (int, float)) for row in mat for item in row):
        row_lengths = [len(str(row)) for row in mat]
        if len(set(row_lengths)) != 1:
            return 'ValueError'

        return [[mat[j][i] for j in range(len(mat))] for i in range(len(mat[0]))]


def row_sums(mat: list[list[float | int]]) -> list[float]:
    if len(mat) == 0:
        return []
    if isinstance(mat, list) and all(isinstance(row, list) for row in mat) \
            and all(isinstance(item, (int, float)) for row in mat for item in row):
        row_lengths = [len(row) for row in mat]
        if len(set(row_lengths)) != 1:
            return 'ValueError'
        return [sum(item) for item in mat]


def col_sums(mat: list[list[float | int]]) -> list[float]:
    if len(mat) == 0:
        return []
    if isinstance(mat, list) and all(isinstance(row, list) for row in mat) \
            and all(isinstance(item, (int, float)) for row in mat for item in row):
        row_lengths = [len(row) for row in mat]
        if len(set(row_lengths)) != 1:
            return 'ValueError'
    result = []
    for col_index in range(len(mat[0])):
        sum_col = 0
        for row in mat:
            sum_col += row[col_index]
        result.append(sum_col)
    return result
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2.2](./images/lab02/matrix2.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2.2](./images/lab02/matrix.png)

### –ó–∞–¥–∞–Ω–∏–µ 3
```python
def format_record(rec: tuple[str, str, float]) -> str:
    if len(rec[0]) == 0 or len(rec[1]) == 0:
        '''–ø—É—Å—Ç–æ–µ –§–ò–û –∏ –ø—É—Å—Ç–∞—è –≥—Ä—É–ø–ø–∞ –∏–º–µ–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ç–∏–ø–∞ –ø–æ—ç—Ç–æ–º—É ValueError'''
        return 'ValueError'
    if type(rec[2]) is not float:
        '''–Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø GPA –∏–º–µ–µ—Ç –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∏–ø–∞(–Ω–∞–ø—Ä–∏–º–µ—Ä int –≤–º–µ—Å—Ç–æ float –ø–æ—ç—Ç–æ–º—É TypeError'''
        return 'TypeError'
    if isinstance(rec, tuple):
        if isinstance(rec[0], str) and isinstance(rec[1], str) and isinstance(rec[2], float):
            name = rec[0].split()
            full_name = name[0][0].upper() + name[0][1:] + ' '
            for initials in name[1:]:
                full_name += initials[0].upper() + '.'
            return f'{full_name}, –≥—Ä. {rec[1]}, GPA {"{:.2f}".format(rec[2])}'
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2.3](./images/lab02/tuples2.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2.3](./images/lab02/tuples.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
import re


def normalize(text: str, *, casefold: bool = True, yo2e: bool = True):
    """
    –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞:
        –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É(–µ—Å–ª–∏ casefold=True)
        –∑–∞–º–µ–Ω—è–µ—Ç —ë/–Å –Ω–∞ –µ/–ï(–µ—Å–ª–∏ yo2e=True)
        —É–±–∏—Ä–∞–µ—Ç –Ω–µ–≤–∏–¥–∏–º—ã–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã
        —Å—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –≤ –æ–¥–∏–Ω
    """
    if isinstance(text, str) and isinstance(casefold, bool) and isinstance(yo2e, bool):
        if casefold:
            text = text.casefold()
        if yo2e:
            text = text.replace('—ë', '–µ')
            text = text.replace('–Å', '–ï')
        if '\t' in text or '\n' in text or '\r' in text:
            text = text.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ')
    return ' '.join(text.split())


def tokenize(text: str) -> list[str]:
    '''
    —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:
        —Å–ª–æ–≤–æ–º —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤ \w (–±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ)
        –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –¥–µ—Ñ–∏—Å –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞
        —á–∏—Å–ª–∞ —Ç–∞–∫–∂–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞–º–∏
        —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –≤—Å–µ –Ω–µ–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
    '''
    if isinstance(text, str):
        text = re.sub(r'[^\w-]', ' ', text).split()
        ''' re.sub - —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–º–µ–Ω—ã –≤ —Ä–µ–≥—É–ª—è—Ä–∫–∞—Ö
            r'[^\w-] - –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ \w (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ) –∏ –¥–µ—Ñ–∏—Å–∞
        '''
    return text


def count_freq(tokens: list[str]) -> dict[str, int]:
    '''–ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å'''
    if isinstance(tokens, list) and all(isinstance(item, str) for item in tokens):
        character_counting = dict()
        for i in (sorted(set(tokens))):
            character_counting[i] = tokens.count(i)
    return character_counting


def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    '''–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø n –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞–º—Å—Ç–æ—Ç—ã; –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ - –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É —Å–ª–æ–≤–∞'''
    if isinstance(freq, dict) \
            and all(isinstance(key, str) and isinstance(value, int) for key, value in freq.items()):
        sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
        '''.items - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
            key=lambda x —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–ª—é—á—É lambda x, –≥–¥–µ x –∞–Ω–æ–Ω–∏–º–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            -x[1] –±–µ—Ä–µ—Ç –≤—Ç–æ—Ä–æ–π —ç–ª–µ–º–µ–Ω—Ç(—á–∞—Å—Ç–æ—Ç—É —Å–ª–æ–≤–∞) –ø–æ —É–±—ã–≤–∞–Ω–∏—é
            x[0] –±–µ—Ä–µ—Ç –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç(—Å–∞–º–æ —Å–ª–æ–≤–æ)
        '''
    return sorted_items[:n]


print("normalize")
print(normalize('–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t'))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
print(normalize("Hello\r\nWorld"))
print(normalize('  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  '))
print()
print("tokenize")
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
print()
print("count_freq")
print(count_freq(["a", "b", "a", "c", "b", "a"]))
print(count_freq(["bb", "aa", "bb", "aa", "cc"]))
print()
print("top_n")
print(top_n({'a': 3, 'b': 2, 'c': 1}, n=2))
print(top_n({"aa": 2, "bb": 2, "cc": 1}, n=2))

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.1](./images/lab03/text2.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.1](./images/lab03/text.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
import sys
'''–¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–π –Ω–∞–º –ø—É—Ç—å –≤ —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π, –≥–¥–µ Python –∏—â–µ—Ç –º–æ–¥—É–ª–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ'''
sys.path.append('C:/Users/matve/PycharmProjects/python_labs/src/lib')
'''–∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ä–∞–Ω–µ–µ —Ñ—É–Ω–∫—Ü–∏–∏'''
from src.lib.moduls import normalize, tokenize, count_freq, top_n
data = sys.stdin.read()
data = [i.casefold() for i in tokenize(normalize(data))]
print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(data)}\n–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(data))}')
f=False
if f:
    longest_word = len(max(count_freq(data), key=len))+5
    print(f'—Å–ª–æ–≤–æ{(longest_word-5) * " "}| —á–∞—Å—Ç–æ—Ç–∞')
    print((longest_word + 9) * '-')
    print('\n'.join([word[0] + ' ' * (longest_word-len(word[0])) + '| ' + str(word[1]) for word in top_n(count_freq(data))]))
else:
    top_words = top_n(count_freq(data))
    print("–¢–æ–ø-5:")
    for word, count in top_words:
        print(f"{word}: {count}")

#hello world hello python test world hello
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.2](./images/lab03/text_stats.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3.2](./images/lab03/text_stats2.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4

### –ó–∞–¥–∞–Ω–∏–µ A ‚Äî –º–æ–¥—É–ª—å src/lab04/io_txt_csv.py
```python
from pathlib import Path
import csv


def ensure_parent_dir(path: str | Path) -> None:
    """
    —Å–æ–∑–¥–∞—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç.
    –∞—Ä–≥—É–º–µ–Ω—Ç—ã:
        path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    """
    path = Path(path)
    parent_dir = path.parent #–ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    parent_dir.mkdir(parents=True, exist_ok=True) # —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏


def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    ''' –æ—Ç–∫—Ä—ã—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏ –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
        –∞—Ä–≥—É–º–µ–Ω—Ç—ã:
            path - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            encoding - –∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é utf-8,
                        –Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –¥—Ä—É–≥–∞—è –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä: encoding="cp1251"
        –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            str: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∫–∞–∫ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
        –û—à–∏–±–∫–∏:
            UnicodeDecodeError: –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É
            FileNotFoundError: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
    '''
    ensure_parent_dir(path)  # —Å–æ–∑–¥–∞—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    try:
        with open(path, 'r', encoding=encoding) as file:
            return ' '.join(file.read().replace("\n", ' ').split())
    except UnicodeDecodeError as e:
        raise ValueError(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞") from e
    except FileNotFoundError as e:
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω") from e


print(read_text('C:/Users/matve/PycharmProjects/python_labs/data/lab04/input.txt'))


def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    ''' –°–æ–∑–¥–∞—Ç—å/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ,
            –∞—Ä–≥—É–º–µ–Ω—Ç—ã:
            rows - —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–¥–æ –∑–∞–ø–∏—Å–∞—Ç—å(—Ç–∞–∫–∂–µ –Ω–∞–¥–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ–± –¥–ª–∏–Ω–∞ –±—ã–ª–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–∞)
                path - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
                header - –∑–∞–≥–æ–ª–æ–≤–æ–∫/1 —Å—Ç—Ä–æ–∫–∞, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Ç–æ –∑–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π
            –û—à–∏–±–∫–∏:
                ValueError: –Ω–µ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ rows –∏–º–µ–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É
        '''
    p = Path(path)
    rows = list(rows)
    ensure_parent_dir(p)  # —Å–æ–∑–¥–∞—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

    ''''–ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É'''
    if rows:
        first_length = len(rows[0])
        for i, row in enumerate(rows):
            if len(row) != first_length:
                raise ValueError(f"–°—Ç—Ä–æ–∫–∞ {i+1} –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(row)}, –æ–∂–∏–¥–∞–µ—Ç—Å—è {first_length}")

    '''–ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª–∏–Ω—ã header —Å –¥–ª–∏–Ω–æ–π —Å—Ç—Ä–æ–∫'''
    if header is not None and rows:
        if len(header) != len(rows[0]):
            raise ValueError(f"Header –∏–º–µ–µ—Ç –¥–ª–∏–Ω—É {len(header)}, –∞ —Å—Ç—Ä–æ–∫–∏ - {len(rows[0])}")

    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)


write_csv([("word","count"),("test",3)], "C:/Users/matve/PycharmProjects/python_labs/data/lab04/check.csv")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.1](./images/lab04/io_txt_csv.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.1](./images/lab04/io_txt_csv1.png)


### –ó–∞–¥–∞–Ω–∏–µ B ‚Äî —Å–∫—Ä–∏–ø—Ç src/lab04/text_report.py
```python
import sys
'''–¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–π –Ω–∞–º –ø—É—Ç—å –≤ —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π, –≥–¥–µ Python –∏—â–µ—Ç –º–æ–¥—É–ª–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ'''
sys.path.append('C:/Users/matve/PycharmProjects/python_labs/src/lib')
'''–∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ä–∞–Ω–µ–µ —Ñ—É–Ω–∫—Ü–∏–∏'''
from src.lib.moduls import normalize, tokenize, count_freq, top_n
from io_txt_csv import read_text, write_csv

def console_output(text): # –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å –∏–∑ —Ñ–∞–π–ª–∞ input.txt
    tokens = top_n(count_freq(tokenize(normalize(text))))
    return f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}\n–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokens))}\n–¢–æ–ø-5:\n{'\n'.join((f'{i[0]}:{i[1]}' for i in tokens))}'

def from_file_to_text(path, encoding='utf-8'): # –ø–µ—Ä–µ–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ input.txt –≤ –µ–¥–∏–Ω—É—é —Å—Ç—Ä–æ–∫—É
    return read_text(path, encoding=encoding)

def frequencies_from_text(text: str) -> dict[str, int]: # —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, —Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –∏–∑ –õ–†3
    tokens = top_n(count_freq(tokenize(normalize(text))))
    return tokens

def text_to_csv(rows, path='C:/Users/matve/PycharmProjects/python_labs/data/lab04/report.csv', header=("word", "count")):
    # –∑–∞–ø–∏—Å—å –≤ scv
    # –µ—Å–ª–∏ —Ñ–∞–π–ª input.txt - –ø—É—Å—Ç–æ–π, —Ç–æ –≤ —Ñ–∞–π–ª–µ report.csv —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    return write_csv(rows, path=path, header=header)

text_to_csv(frequencies_from_text(from_file_to_text('C:/Users/matve/PycharmProjects/python_labs/data/lab04/input.txt')))
print(console_output(from_file_to_text('C:/Users/matve/PycharmProjects/python_labs/data/lab04/input.txt')))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4.2](./images/lab04/text_report.png)

